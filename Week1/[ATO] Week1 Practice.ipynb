{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AlphaToOmega](https://i.imgur.com/JdERPuK.png)\n",
    "\n",
    "## Machine Learning Study Week1\n",
    "\n",
    "## : Lec 0 ~ 4\n",
    "\n",
    "### 2017년 12월 27일 안상호\n",
    "\n",
    "머신러닝, 텐서 플로우, 선형회귀\n",
    "\n",
    "---\n",
    "\n",
    "### 목차\n",
    "\n",
    "1. **Lec00 & Lec01**: 머신러닝의 기본 + TensorFlow 기초 \n",
    "2. **Lec02**: 선형회귀 기초 \n",
    "3. **Lec03**: Cost 최소화 알고리즘\n",
    "4. **Lec04**: 다변수 선형 회귀 \n",
    "5. **Optional**: Feature Scaling and Normal Equation\n",
    "\n",
    "---\n",
    "\n",
    "## Lec00: 머신러닝 OT \n",
    "\n",
    "---\n",
    "\n",
    "## Lec01: 머신러닝의 기본\n",
    "\n",
    "### Tensorflow의 설치 및 기본적인 operations\n",
    "\n",
    "+ TensorFlow란?\n",
    "\n",
    "> edges와 nodes로 구조화된 graph로 프로그램이 구성\n",
    "\n",
    "![](http://cfile29.uf.tistory.com/image/2256FA33596D8E70299A90)\n",
    "\n",
    "여기서 nodes는 어떤 동작이 일어나는지에 관한 operation이고 (쉽게 말해 함수)\n",
    "\n",
    "edges는 이러한 nodes를 동작시키기 위한 Data, Tensor이다.\n",
    "\n",
    "Data가 여러 Operation 들을 통해 연결되고 연산됨을 생각해보며 밑의 예제들을 풀어나가보자\n",
    "\n",
    "---\n",
    "\n",
    "### 1.1. Hello TensorFlow!\n",
    "\n",
    "- Check installation and version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 역시 프로그래밍은 \"Hello, World\" 부터 시작!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, TensorFlow!\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant(\"Hello, TensorFlow!\") ### hello라는 node\n",
    "\n",
    "# start a TF session\n",
    "sess = tf.Session()\n",
    "\n",
    "# run the op and get result\n",
    "print(sess.run(hello)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.2. Computational Graph\n",
    "\n",
    "> TensorFlow로 코딩을 하면 크게 3단계로 나누어진다. \n",
    ">> 1. Init: 처음에 변수를 만들어 주는 단계\n",
    ">> 2. Build: 만들어진 변수들을 통해 모델을 만드는 단계\n",
    ">> 3. Run: 만들어진 모델에 데이터를 주어서 실행 or 그냥 실행 \n",
    "\n",
    "> 밑의 예제를 통해서는 텐서플로우가 어떠한 방법을 거쳐서 결과를 내는지를 보도록하자\n",
    "\n",
    "> P.S. 강의에서는 Build -> Feed&Run -> Update 순이다\n",
    "> [ML lab01](https://youtu.be/-57Ne86Ia8w)\n",
    "\n",
    "#### 1.2.1. Build graph(tensors) using TensorFlow operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('node1:', <tf.Tensor 'Const_1:0' shape=() dtype=float32>, 'node2:', <tf.Tensor 'Const_2:0' shape=() dtype=float32>)\n",
      "('node3: ', <tf.Tensor 'Add:0' shape=() dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0) # also tf.float32 implicitly\n",
    "node3 = tf.add(node1, node2)\n",
    "\n",
    "print(\"node1:\", node1, \"node2:\", node2)\n",
    "print(\"node3: \", node3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 설명 \n",
    "\n",
    "    난 노드(op)야! 라고 말하고 있는 것을 확인할 수 있다.\n",
    "\n",
    "    즉, 노드를 실행을 위해서는 다른 방법이 필요!\n",
    "\n",
    "#### 1.2.2. Feed data and run graph sess.run(op)\n",
    "\n",
    "### and\n",
    "\n",
    "#### 1.2.3. Update variables in the graph (and return values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sess.run(node1, node2): ', [3.0, 4.0])\n",
      "('sess.run(node3): ', 7.0)\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(\"sess.run(node1, node2): \", sess.run([node1, node2]))\n",
    "print(\"sess.run(node3): \", sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### 1.3. Data Type\n",
    "\n",
    "> 텐서플로우는 뉴럴네트워크에 최적화되어 있는 개발 프레임웤이기 때문에, 그 자료형과, 실행 방식이 약간 일반적인 프로그래밍 방식과 상이하다. 그래서 삽질(?)을 많이했다\n",
    "\n",
    "[조대협의 블로그](http://bcho.tistory.com/1150)\n",
    "\n",
    "#### 1.3.1. 상수형 (Constant)\n",
    "\n",
    "간단히 말해서 상수인 값들을 할당한다\n",
    "\n",
    "- tf.constant(value, dtype=None, shape=None, name='Const', verify_shape=False)\n",
    "    + value: 상수 값\n",
    "    + dtype: 저장되는 데이터 타입. tf.float32와 같이 실수, 정수 등의 데이터 타입을 정의한다. \n",
    "    + shape: 행렬 차원 정의! m by n 행렬\n",
    "    + name: 상수의 이름을 정의한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run(node1): 3.0\n"
     ]
    }
   ],
   "source": [
    "# Build\n",
    "node1 = tf.constant(3.0, tf.float32)\n",
    "\n",
    "# Run\n",
    "sess = tf.Session()\n",
    "print(\"sess.run(node1): {}\".format(sess.run(node1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2. 플레이스 홀더 (Placeholder)\n",
    "\n",
    "간단히 말해 빈 변수를 만들어주고, 값이 입력 되기를 기다리는 것이다!\n",
    "\n",
    "이렇게 해서 모델을 먼저 만들고나면 어떤 값이든 부여할 수 있게 된다. \n",
    "\n",
    "즉, 학습을 위한 학습용 데이터 타입!\n",
    "\n",
    "- tf.tf.placeholder(dtype,shape,name) \n",
    "    + dytpe: 저장되는 데이터 타입\n",
    "    + shape: 행렬 차원 정의! m by n 행렬\n",
    "    + name: placeholder의 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run(node1): 3.0\n",
      "sess.run(node1): 1.0\n"
     ]
    }
   ],
   "source": [
    "# Build\n",
    "\n",
    "node_data1 = 3.0\n",
    "node_data2 = 1.0\n",
    "node1 = tf.placeholder(tf.float32)\n",
    "\n",
    "# Run\n",
    "sess = tf.Session()\n",
    "print(\"sess.run(node1): {}\".format(sess.run(node1, feed_dict={node1: node_data1})))\n",
    "print(\"sess.run(node1): {}\".format(sess.run(node1, feed_dict={node1: node_data2})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`feed_dict` 로 데이터를 할당해주는 것에 주목하자 \n",
    "\n",
    "#### 1.3.3. 변수형 (Variable)\n",
    "\n",
    "모델을 통한 학습이 진행될 때, 계속해서 값을 \n",
    "\n",
    "업데이트하는 식으로 바꾸어주어야 하는 값들이 있다.\n",
    "\n",
    "그 변수들을 위한 자료형!\n",
    "\n",
    "`trainable` 값, 즉 학습시 tensorflow가 변경 가능한 값 \n",
    "\n",
    "- tf.Variable.__init__(initial_value=None, trainable=True, collections=None, validate_shape=True, caching_device=None, name=None, variable_def=None, dtype=None, expected_shape=None, import_scope=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.   4.   6.   8.  10.]\n"
     ]
    }
   ],
   "source": [
    "node_data = [1,2,3,4,5]\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "W = tf.Variable([2],dtype=tf.float32)\n",
    "\n",
    "y = W*x\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "result = sess.run(y,feed_dict={x:node_data})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "밑에서 학습에 따라 변화하는 W를 보도록 하자\n",
    "\n",
    "---\n",
    "\n",
    "## Lec02: 선형 회귀 (Linear Regression) 기초\n",
    "\n",
    "### TensorFlow로 간단한 linear regression을 구현\n",
    "\n",
    "> 상관 관계에 관해서는 다들 한번씩 들어보았을 것이다. 그렇지만 두변수가 높은 상관 관계를 보이고 있다고 해서 이것들 간에 인과관계가 있는 것은 아니다. 바로 이 회귀 분석 방법이 인과관계를 찾아가는 과정이라고 생각하면 된다. 다음과 같은 Step을 따른다.\n",
    "\n",
    ">> **Step1**: 가설 설정 - `Hypothesis` (Build)\n",
    "\n",
    ">> **Step2**: 비용 계산식 설정 - `Cost` (Build)\n",
    "\n",
    ">> **Step3**: 비용 최소화식 설정 - `Gradient Descent` (Build)\n",
    "\n",
    ">> **Step4**: 실행 (Run)\n",
    "\n",
    "---\n",
    "\n",
    "### 2.1. Hypothesis 설정 \n",
    "\n",
    "$$H(x) = Wx + b$$\n",
    "\n",
    "- **Def**\n",
    "    + X에 대한 Y 값을 예측해주는 가설"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed(777)  # 재연을 위한 난수표\n",
    "\n",
    "# X and Y data\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name= 'Weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name= 'bias')\n",
    "\n",
    "hypothesis = x_train*W + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.2. Cost 계산\n",
    "\n",
    "$$cost(W,b) = \\frac{1}{m}\\sum_{i=1}^{m} (H(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "- **Def**\n",
    "    + 우리가 만든 식에 따른 예측 값이 실제 y 값과 얼마나 차이가 나는가?\n",
    "    \n",
    "    > H는 예측 값, y는 실제 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.square()` : 제곱 (2)\n",
    "\n",
    "`tf.reduce_mean()`: 평균 내주는 것 (1/m) \n",
    "\n",
    "---\n",
    "\n",
    "### 2.3. Cost 최소화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.4. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 세션 열고\n",
    "2. `tf.global_variables_initializer()`: 변수형과 세트! 그래프를 실행하기 전에 초기화하여 W에 지정한 값이 변수에 지정되도록 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stpe: 0, Cost: 20.7623004913, Weight: [-1.05880177], bias: [-0.11754983]\n",
      "Stpe: 200, Cost: 0.0238858964294, Weight: [ 0.82049912], bias: [ 0.4080478]\n",
      "Stpe: 400, Cost: 0.00912080984563, Weight: [ 0.88907933], bias: [ 0.25214887]\n",
      "Stpe: 600, Cost: 0.00348277133889, Weight: [ 0.93145776], bias: [ 0.15581261]\n",
      "Stpe: 800, Cost: 0.00132989371195, Weight: [ 0.957645], bias: [ 0.0962828]\n",
      "Stpe: 1000, Cost: 0.000507819058839, Weight: [ 0.97382718], bias: [ 0.05949693]\n",
      "Stpe: 1200, Cost: 0.000193909931113, Weight: [ 0.98382676], bias: [ 0.03676552]\n",
      "Stpe: 1400, Cost: 7.40457689972e-05, Weight: [ 0.99000591], bias: [ 0.02271891]\n",
      "Stpe: 1600, Cost: 2.82737673842e-05, Weight: [ 0.9938243], bias: [ 0.0140388]\n",
      "Stpe: 1800, Cost: 1.07965161078e-05, Weight: [ 0.99618381], bias: [ 0.00867511]\n",
      "Stpe: 2000, Cost: 4.12263989347e-06, Weight: [ 0.99764174], bias: [ 0.00536075]\n"
     ]
    }
   ],
   "source": [
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 200 == 0:\n",
    "        print(\"Stpe: {}, Cost: {}, Weight: {}, bias: {}\".format(step, sess.run(cost), sess.run(W), sess.run(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "200번의 연산마다 Cost, Weight, bias 순으로 출력해보았다.\n",
    "\n",
    "데이터 셋에서 생각할 수 있는\n",
    "\n",
    "$y = x$ 가 $y = 0.997x + 0.005$로 거의 근사 값에 도달 했음을 알 수 있다.\n",
    "\n",
    "### Placeholder Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 9.5306149, array([ 0.41279173], dtype=float32), array([ 0.65492594], dtype=float32))\n",
      "(200, 0.0032533661, array([ 1.03690577], dtype=float32), array([ 0.96675861], dtype=float32))\n",
      "(400, 0.00083946588, array([ 1.01874697], dtype=float32), array([ 1.03231752], dtype=float32))\n",
      "(600, 0.00021661093, array([ 1.0095228], dtype=float32), array([ 1.06561923], dtype=float32))\n",
      "(800, 5.5890334e-05, array([ 1.00483716], dtype=float32), array([ 1.08253598], dtype=float32))\n",
      "(1000, 1.4422332e-05, array([ 1.00245726], dtype=float32), array([ 1.09112847], dtype=float32))\n",
      "(1200, 3.7224386e-06, array([ 1.00124824], dtype=float32), array([ 1.09549308], dtype=float32))\n",
      "(1400, 9.6060671e-07, array([ 1.00063431], dtype=float32), array([ 1.09771037], dtype=float32))\n",
      "(1600, 2.4803353e-07, array([ 1.00032246], dtype=float32), array([ 1.0988363], dtype=float32))\n",
      "(1800, 6.4208244e-08, array([ 1.00016379], dtype=float32), array([ 1.09940815], dtype=float32))\n",
      "(2000, 1.6620209e-08, array([ 1.00008345], dtype=float32), array([ 1.0996989], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([1]), name= 'Weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name= 'bias')\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None]) ### shope = None 무슨 값들어와도 상관 없음 \n",
    "y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "hypothesis = X*W + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train], feed_dict = {X: [1,2,3,4,5], y: [2.1,3.1,4.1,5.1,6.1]})\n",
    "    \n",
    "    if step % 200 == 0:\n",
    "        print(step, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = x + 1.1$ 이 $y = 1.000x + 1.099$으로 거의 근사 값에 도달 했음을 알 수 있다.\n",
    "\n",
    "### Test out model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.10011625]\n",
      "[ 3.5999074]\n",
      "[ 2.59982395  4.59999084]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hypothesis, feed_dict = {X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict = {X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict = {X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lec03: Cost 최소화 알고리즘\n",
    "\n",
    "## Linear Regression의 cost 최소화의 TensorFlow 구현\n",
    "\n",
    "$$cost(W) = \\frac{1}{m}\\sum_{i=1}^{m} (W(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "$$cost(W) = \\frac{1}{2m}\\sum_{i=1}^{m} (W(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "> 미분시 수식을 간단하게 하기 위한 것\n",
    ">> 대표적인 cost 최소화 알고리즘인 Gradient Descent 사용\n",
    "\n",
    "$$W := W - \\alpha \\frac{\\partial}{\\partial W}cost(W)$$\n",
    "$$W := W - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (W(x^{(i)}) - y^{(i)})x^{(i)}$$\n",
    "\n",
    "> Cost Function이 반드시 Convex 형태가 되게 할것 (오목 그래프)\n",
    ">> 이렇게 해야 어디서 출발해도 한점으로 수렴하게 된다\n",
    "\n",
    "<br>\n",
    "\n",
    "+ Convex Function 여부 확인하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f38afa43b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "W = tf.placeholder(tf.float32)\n",
    "\n",
    "# Our hypothesis for linear model X * W\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Variables for plotting cost function\n",
    "W_history = []\n",
    "cost_history = []\n",
    "\n",
    "for i in range(-30, 50): \n",
    "    curr_W = i * 0.1\n",
    "    curr_cost = sess.run(cost, feed_dict={W: curr_W})\n",
    "    W_history.append(curr_W)\n",
    "    cost_history.append(curr_cost)\n",
    "\n",
    "# Show the cost function\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(W_history, cost_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.1. Build - Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name= 'Weight')\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(W*X - Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.2. Build - Minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize: Gradient Descent using derivative: W -= learning_rate * derivative\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * X - Y) * X)\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.3. Run - Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.043867558, array([ 0.90304542], dtype=float32))\n",
      "(1, 0.012477879, array([ 0.94829088], dtype=float32))\n",
      "(2, 0.0035492636, array([ 0.97242182], dtype=float32))\n",
      "(3, 0.0010095664, array([ 0.98529166], dtype=float32))\n",
      "(4, 0.00028716505, array([ 0.99215555], dtype=float32))\n",
      "(5, 8.1682148e-05, array([ 0.99581629], dtype=float32))\n",
      "(6, 2.3233662e-05, array([ 0.9977687], dtype=float32))\n",
      "(7, 6.6086832e-06, array([ 0.99880999], dtype=float32))\n",
      "(8, 1.8797629e-06, array([ 0.99936533], dtype=float32))\n",
      "(9, 5.3466027e-07, array([ 0.99966151], dtype=float32))\n",
      "(10, 1.5213425e-07, array([ 0.99981946], dtype=float32))\n",
      "(11, 4.323115e-08, array([ 0.99990374], dtype=float32))\n",
      "(12, 1.2296725e-08, array([ 0.99994868], dtype=float32))\n",
      "(13, 3.4896896e-09, array([ 0.99997264], dtype=float32))\n",
      "(14, 9.9691633e-10, array([ 0.9999854], dtype=float32))\n",
      "(15, 2.8358826e-10, array([ 0.99999219], dtype=float32))\n",
      "(16, 8.0248697e-11, array([ 0.99999583], dtype=float32))\n",
      "(17, 2.3405278e-11, array([ 0.99999774], dtype=float32))\n",
      "(18, 6.6317321e-12, array([ 0.99999881], dtype=float32))\n",
      "(19, 1.9291235e-12, array([ 0.99999934], dtype=float32))\n",
      "(20, 5.163277e-13, array([ 0.99999964], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(21):\n",
    "    sess.run(update, feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.4. GradientDescentOptimizer 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "# W = tf.Variable(tf.random_normal([1]), name= 'Weight')\n",
    "W = tf.Variable(-300.0)\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(W*X - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, -300.0)\n",
      "(1, -19.06665)\n",
      "(2, -0.33777618)\n",
      "(3, 0.910815)\n",
      "(4, 0.99405432)\n",
      "(5, 0.99960363)\n",
      "(6, 0.9999736)\n",
      "(7, 0.99999821)\n",
      "(8, 0.99999988)\n",
      "(9, 1.0)\n",
      "(10, 1.0)\n",
      "(11, 1.0)\n",
      "(12, 1.0)\n",
      "(13, 1.0)\n",
      "(14, 1.0)\n",
      "(15, 1.0)\n",
      "(16, 1.0)\n",
      "(17, 1.0)\n",
      "(18, 1.0)\n",
      "(19, 1.0)\n",
      "(20, 1.0)\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(21):\n",
    "    print(step, sess.run(W))\n",
    "    sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "#     sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "#     print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz! \n",
    "\n",
    "다들 강의에서 외부에 있는 데이터를 가져오는 방법은 배우셨을 것입니다!\n",
    "\n",
    "다들 새로운 데이터를 가지고 회귀모델을 만들어 보도록합시다.\n",
    "\n",
    "준비한 데이터에 관한 설명입니다. \n",
    "\n",
    "> The first column is the population of a city \n",
    "\n",
    "> the second column is the profit of a food truck in that city.\n",
    "\n",
    "이제 아래 질문에 대한 답을 찾아주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "# Data Load\n",
    "data = np.loadtxt('data/ex1data1.txt', delimiter=',')\n",
    "\n",
    "X_data = data[:,0]\n",
    "y_data = data[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `R`로 치면 `ggplot2`와 비슷한 `matplotlib`으로 데이터의 시각화를 해보십니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,u'Profit in $10,000s')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f38643ddad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X_data, y_data, s=30, c='r', marker='x', linewidths=1)\n",
    "plt.xlim(4,24)\n",
    "plt.xlabel('Population of City in 10,000s')\n",
    "plt.ylabel('Profit in $10,000s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 위 데이터에 적합한 Weight와 bias를 구하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 인구 값이 `6.1101` 일 때 푸드트럭의 예상 수익은 얼마입니까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lec04: 다변수 선형 회귀\n",
    "\n",
    "## multi-variable linear regression을 TensorFlow에서 구현하기\n",
    "\n",
    "---\n",
    "\n",
    "### 4.1. without Matrix\n",
    "\n",
    "#### 4.1.1. Build - init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_4:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x1_data = [73., 93., 89., 96., 73.] \n",
    "x2_data = [80., 88., 91., 98., 66.] \n",
    "x3_data = [75., 93., 90., 100., 70.] \n",
    "\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2. Build - minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize. Need a very small learning rate for this data set\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3. Run - Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Cost: 75184.25 \n",
      "Prediction:\n",
      " [ -82.44986725 -114.04092407 -104.40079498 -115.73933411  -89.22245789]  Weight: [-0.50869608] | [ 1.32636857] | [-0.57816505]\n",
      "Step: 200 Cost: 37.1485404968 \n",
      "Prediction:\n",
      " [ 160.29223633  178.63548279  183.50038147  197.83311462  134.19862366]  Weight: [ 0.14281878] | [ 1.84976411] | [ 0.03848489]\n",
      "Step: 400 Cost: 33.3534584045 \n",
      "Prediction:\n",
      " [ 159.83123779  178.95144653  183.35902405  197.73156738  134.6126709 ]  Weight: [ 0.1961917] | [ 1.78234279] | [ 0.05230054]\n",
      "Step: 600 Cost: 29.9481868744 \n",
      "Prediction:\n",
      " [ 159.39453125  179.25074768  183.22509766  197.63542175  135.00485229]  Weight: [ 0.24673891] | [ 1.71847367] | [ 0.06540171]\n",
      "Step: 800 Cost: 26.8927574158 \n",
      "Prediction:\n",
      " [ 158.98083496  179.53425598  183.09825134  197.54440308  135.37632751]  Weight: [ 0.2946099] | [ 1.65796876] | [ 0.0778264]\n",
      "Step: 1000 Cost: 24.1511478424 \n",
      "Prediction:\n",
      " [ 158.58895874  179.80285645  182.97808838  197.45819092  135.72817993]  Weight: [ 0.33994535] | [ 1.6006515] | [ 0.08960984]\n",
      "Step: 1200 Cost: 21.6912631989 \n",
      "Prediction:\n",
      " [ 158.21775818  180.05728149  182.86425781  197.37657166  136.06144714]  Weight: [ 0.38287988] | [ 1.54635262] | [ 0.10078611]\n",
      "Step: 1400 Cost: 19.483997345 \n",
      "Prediction:\n",
      " [ 157.86607361  180.29826355  182.75637817  197.29927063  136.37709045]  Weight: [ 0.42353931] | [ 1.49491417] | [ 0.11138677]\n",
      "Step: 1600 Cost: 17.5035171509 \n",
      "Prediction:\n",
      " [ 157.53295898  180.52655029  182.65420532  197.22610474  136.67608643]  Weight: [ 0.46204406] | [ 1.44618487] | [ 0.12144222]\n",
      "Step: 1800 Cost: 15.7264556885 \n",
      "Prediction:\n",
      " [ 157.21740723  180.74281311  182.55743408  197.15681458  136.95930481]  Weight: [ 0.49850798] | [ 1.40002131] | [ 0.13098137]\n",
      "Step: 2000 Cost: 14.131980896 \n",
      "Prediction:\n",
      " [ 156.91848755  180.94767761  182.46572876  197.09120178  137.2275238 ]  Weight: [ 0.53303891] | [ 1.35628879] | [ 0.14003097]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                   feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
    "    if step % 200 == 0:\n",
    "        print(\"Step: {} Cost: {} \\nPrediction:\\n {}  Weight: {} | {} | {}\".format(step, cost_val, hy_val, sess.run(w1), sess.run(w2), sess.run(w3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4.2. with Matrix\n",
    "\n",
    "#### 4.2.1. Build - init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[73., 80., 75.],\n",
    "          [93., 88., 93.],\n",
    "          [89., 91., 90.],\n",
    "          [96., 98., 100.],\n",
    "          [73., 66., 70.]]\n",
    "y_data = [[152.],\n",
    "          [185.],\n",
    "          [180.],\n",
    "          [196.],\n",
    "          [142.]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3]) ### n X 3\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1]) ### n X 1\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight') ### (n X 3) X () = (n X 1)\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 `x1`, `x2`, `x3`로 표시되던 column들이 행렬 형태로 묶여 있는 것을 확인할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2. Build - minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3. Run - Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost: 399874.375 \n",
      "Prediction:\n",
      " [[-410.13574219]\n",
      " [-489.04779053]\n",
      " [-483.70129395]\n",
      " [-530.41278076]\n",
      " [-368.7444458 ]]\n",
      "200 Cost: 4.36271762848 \n",
      "Prediction:\n",
      " [[ 151.05220032]\n",
      " [ 185.26654053]\n",
      " [ 180.81062317]\n",
      " [ 193.22831726]\n",
      " [ 145.53622437]]\n",
      "400 Cost: 4.1537566185 \n",
      "Prediction:\n",
      " [[ 151.14730835]\n",
      " [ 185.1998291 ]\n",
      " [ 180.83784485]\n",
      " [ 193.26283264]\n",
      " [ 145.43623352]]\n",
      "600 Cost: 3.96401286125 \n",
      "Prediction:\n",
      " [[ 151.23707581]\n",
      " [ 185.1368103 ]\n",
      " [ 180.86346436]\n",
      " [ 193.29611206]\n",
      " [ 145.34106445]]\n",
      "800 Cost: 3.79164505005 \n",
      "Prediction:\n",
      " [[ 151.32180786]\n",
      " [ 185.07725525]\n",
      " [ 180.88749695]\n",
      " [ 193.32818604]\n",
      " [ 145.25054932]]\n",
      "1000 Cost: 3.63487696648 \n",
      "Prediction:\n",
      " [[ 151.40171814]\n",
      " [ 185.02099609]\n",
      " [ 180.91011047]\n",
      " [ 193.35913086]\n",
      " [ 145.16441345]]\n",
      "1200 Cost: 3.49209022522 \n",
      "Prediction:\n",
      " [[ 151.47709656]\n",
      " [ 184.96781921]\n",
      " [ 180.93132019]\n",
      " [ 193.38899231]\n",
      " [ 145.08241272]]\n",
      "1400 Cost: 3.36187553406 \n",
      "Prediction:\n",
      " [[ 151.54818726]\n",
      " [ 184.91766357]\n",
      " [ 180.95126343]\n",
      " [ 193.4178772 ]\n",
      " [ 145.00436401]]\n",
      "1600 Cost: 3.24296236038 \n",
      "Prediction:\n",
      " [[ 151.61520386]\n",
      " [ 184.87025452]\n",
      " [ 180.96994019]\n",
      " [ 193.44577026]\n",
      " [ 144.93002319]]\n",
      "1800 Cost: 3.13424110413 \n",
      "Prediction:\n",
      " [[ 151.67840576]\n",
      " [ 184.82550049]\n",
      " [ 180.98742676]\n",
      " [ 193.47273254]\n",
      " [ 144.85923767]]\n",
      "2000 Cost: 3.03465270996 \n",
      "Prediction:\n",
      " [[ 151.73791504]\n",
      " [ 184.78323364]\n",
      " [ 181.00382996]\n",
      " [ 193.49884033]\n",
      " [ 144.79179382]]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 200 == 0:\n",
    "        print(\"{} Cost: {} \\nPrediction:\\n {}\".format(step, cost_val, hy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 151.73820496],\n",
       "       [ 184.78303528],\n",
       "       [ 181.00390625],\n",
       "       [ 193.4989624 ],\n",
       "       [ 144.79145813]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(hypothesis, feed_dict={X: x_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[152.],\n",
    "[185.],\n",
    "[180.],\n",
    "[196.],\n",
    "[142.]]\n",
    "\n",
    "# Quiz! \n",
    "\n",
    "당연히 이번에도 있겠죠! \n",
    "\n",
    "다들 새로운 데이터를 가지고 다변수 선형 회귀모델을 만들어 보도록합시다.\n",
    "\n",
    "준비한 데이터에 관한 설명입니다. \n",
    "\n",
    "> The first column is the size of the house (in square feet) \n",
    "\n",
    "> the second column is the number of bedrooms\n",
    "\n",
    "> the third column is the price of the house.\n",
    "\n",
    "이제 아래 질문에 대한 답을 찾아주세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 위 데이터에 적합한 Weight와 bias를 구하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 평방 미터 제곱 값이 `2104`, 방의 갯수가 `3`일 때 에측되는 집값은 얼마입니까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 고생하셨습니다! \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Feature Scaling and Normal Equation\n",
    "\n",
    "---\n",
    "\n",
    "### 5.1. Feature Scaling \n",
    "\n",
    "> 위의 퀴즈에서 본 것처럼 집 평방 미터 제곱 값과 방의 갯수에 관한 두 Feature는 매우 상이한 범위를 가지고 있다. 그래서 Gradient Descent 방법에서 상당히 많은 시간을 요구하게 된다. 그래서 사용하는 방법이 바로 **Feature Scaling** 이다. 상이한 범위를 가진 데이터들의 범위를 같게 만들어 주어서 더욱 빠르게 수렴하도록 만든다. \n",
    "\n",
    ">> 스케일링 해주는 방법은 데이터들을 각각 해당 열의 평균에서 뺀 값을 해당 열의 표준편차로 나누어주는 방법이 대표적이다. 혹은 최댓 값에서 최솟값을 빼준 값으로 나누어 주어도 무방하다. \n",
    "\n",
    "$$x_1 = \\frac{size(feet^2) - mean(size)}{\\sigma}$$\n",
    "$$x_2 = \\frac{numBedrooms - mean(num)}{\\sigma}$$\n",
    "\n",
    "#### 5.1.1. 데이터 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((47, 2), (47, 1))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "# Data Load\n",
    "data = np.loadtxt('data/ex1data2.txt', delimiter=',')\n",
    "\n",
    "X_data = data[:,0:-1]\n",
    "y_data = data[:,[-1]] \n",
    "# y_data = data[:,-1] 차이는 47로 구성된 벡터냐, 아니면 47X1 행렬이냐\n",
    "print(X_data.shape, y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2.  Feature Sacaling 함수\n",
    "\n",
    "+ X의 평균 값 리스트와 표준편차 리스트도 함께 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "def FeatureScale(data):\n",
    "    data_shape = data.shape\n",
    "    data_mean, data_std = [], []\n",
    "\n",
    "    data_norm = np.zeros(data_shape)   \n",
    "    for i in range(data_shape[1]):\n",
    "        data_i = data[:,i]\n",
    "        m = data_i.mean()\n",
    "        s = data_i.std()\n",
    "        \n",
    "        data_norm[:,i] = (data_i - m)/(s)\n",
    "        data_mean.append(m)\n",
    "        data_std.append(s)\n",
    "        \n",
    "    return data_norm, data_mean, data_std\n",
    "\n",
    "# (X_data - X_data.mean())/X_data.std()\n",
    "X_norm, X_mean, X_std = FeatureScale(X_data)\n",
    "y_norm, y_mean, y_std = FeatureScale(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.3. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, array([[-0.40810791],\n",
      "       [-0.68814003]], dtype=float32), array([ 0.98412555], dtype=float32), 4.2296381)\n",
      "(200, array([[ 0.82691532],\n",
      "       [ 0.00126802]], dtype=float32), array([ 0.01730874], dtype=float32), 0.2701382)\n",
      "(400, array([[ 0.87517917],\n",
      "       [-0.04359798]], dtype=float32), array([ 0.00030442], dtype=float32), 0.26713592)\n",
      "(600, array([[ 0.88313013],\n",
      "       [-0.05154299]], dtype=float32), array([  5.34627270e-06], dtype=float32), 0.26705736)\n",
      "(800, array([[ 0.88448673],\n",
      "       [-0.05289959]], dtype=float32), array([  8.62744827e-08], dtype=float32), 0.26705506)\n",
      "(1000, array([[ 0.88471818],\n",
      "       [-0.05313111]], dtype=float32), array([ -3.25819127e-09], dtype=float32), 0.26705498)\n",
      "(1200, array([[ 0.88475728],\n",
      "       [-0.05317054]], dtype=float32), array([ -1.55982054e-08], dtype=float32), 0.26705498)\n",
      "(1400, array([[ 0.88476354],\n",
      "       [-0.05317702]], dtype=float32), array([ -1.53281139e-08], dtype=float32), 0.26705498)\n",
      "(1600, array([[ 0.88476378],\n",
      "       [-0.05317748]], dtype=float32), array([ -1.49369548e-08], dtype=float32), 0.26705498)\n",
      "(1800, array([[ 0.88476378],\n",
      "       [-0.05317748]], dtype=float32), array([ -1.48996770e-08], dtype=float32), 0.26705498)\n",
      "(2000, array([[ 0.88476378],\n",
      "       [-0.05317748]], dtype=float32), array([ -1.48623993e-08], dtype=float32), 0.26705498)\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, 2])\n",
    "y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name= 'Weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name= 'bias')\n",
    "\n",
    "# Build \n",
    "\n",
    "h = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(h - y))\n",
    "# 3e-3\n",
    "# 1e-10\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Run\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(train, feed_dict= {X: X_norm, y: y_norm})\n",
    "    if step % 200 == 0:\n",
    "        print(step, sess.run(W), sess.run(b), sess.run(cost, feed_dict= {X: X_norm, y: y_norm}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.4. Prediction\n",
    "\n",
    "- **input** 값을 Feature Scaling 형태로 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.13141542 -0.22609337]]\n",
      "(array([[ 0.12829466]], dtype=float32), array([[ 0.88476378],\n",
      "       [-0.05317748]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# Build\n",
    "\n",
    "X_test = np.array([[2104, 3]])\n",
    "X_test= (X_test- X_mean)/X_std\n",
    "print(X_test)\n",
    "\n",
    "# Run\n",
    "print(sess.run(h, feed_dict= {X: X_test} ), sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Prediction** 값이 스케일링 되어 있으므로, 다시 원 값으로 돌림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356283.03437251452"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = 0.12829466*y_std[0] + y_mean[0]\n",
    "\n",
    "# prediction - 399900\n",
    "prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5.2. Normal Equation \n",
    "\n",
    "> 행렬의 역행렬을 이용하면 Gradient Descent 없이도 바로 Weight 값을 구할 수 있다는 놀라운 사실\n",
    "\n",
    ">> 하지만 n^3의 컴퓨팅 파워가 소모\n",
    "\n",
    "$$ X\\theta = y$$\n",
    "\n",
    "$$ \\theta = (X^TX)^{-1}X^Ty$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.loadtxt('data/ex1data2.txt', delimiter=',')\n",
    "\n",
    "X_data = data[:,0:-1] ### 47 X 3 -> Transpose 3 X 47\n",
    "y_data = data[:,[-1]] \n",
    "\n",
    "# x_data = np.array([[73., 80., 75.],\n",
    "#                    [93., 88., 93.],\n",
    "#                    [89., 91., 90.],\n",
    "#                    [96., 98., 100.],\n",
    "#                    [73., 66., 70.]])\n",
    "# y_data = np.array([[152.],\n",
    "#                    [185.],\n",
    "#                    [180.],\n",
    "#                    [196.],\n",
    "#                    [142.]])\n",
    "\n",
    "x_inv = np.linalg.pinv(X_data)\n",
    "\n",
    "# theta = x_inv.dot(y_data)\n",
    "theta = np.linalg.pinv(X_data.T.dot(X_data)).dot(X_data.T.dot(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 334628.80080581]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[2014, 3]]).dot(theta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
